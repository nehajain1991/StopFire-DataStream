{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka Event Producer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted by : Mayank Bhardwaj, Neha Jain, Rishupal Singh Chabbra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, we have created an Event Producer using Kafka Producer. This will act as Producer 1 for the streaming data and will randomly produce the data for climate_streaming.csv at an interval of 5 seconds each. Additionally, sender_id = \"P1\" and created_time = current timestamp is appended to the record so as to identify the producer at the consumer end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic \"climate\" is used for the Kafka stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "climate_streaming = []\n",
    "with open('climate_streaming.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file,delimiter=',')\n",
    "    headers = next(csv_reader)    #skipping header\n",
    "    for row in csv_reader:\n",
    "        # loading each row as json record and appending to a list so as to send to the consumer\n",
    "        record = {'latitude': row[0]  , \n",
    "                  'longitude': row[1] , \n",
    "                  'air_temperature_celcius': row[2] , \n",
    "                  'relative_humidity': row[3] , \n",
    "                  'windspeed_knots': row[4] , \n",
    "                  'max_wind_speed': row[5] , \n",
    "                  'precipitation' : row[6],\n",
    "                  'sender_id':'P1'            \n",
    "        }\n",
    "        \n",
    "        climate_streaming.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbiEkY6F4FX9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '13', 'windspeed_knots': '9.3', 'created_time': '2019-05-28 01:05:59', 'latitude': '-37.611', 'longitude': '149.277', 'air_temperature_celcius': '18', 'relative_humidity': '49.4'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '14', 'windspeed_knots': '7.9', 'created_time': '2019-05-28 01:06:04', 'latitude': '-37.858', 'longitude': '143.428', 'air_temperature_celcius': '13', 'relative_humidity': '50.4'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00G', 'max_wind_speed': '20', 'windspeed_knots': '14.4', 'created_time': '2019-05-28 01:06:09', 'latitude': '-37.5268', 'longitude': '143.0551', 'air_temperature_celcius': '8', 'relative_humidity': '35'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '14', 'windspeed_knots': '7.9', 'created_time': '2019-05-28 01:06:14', 'latitude': '-36.275', 'longitude': '146.154', 'air_temperature_celcius': '18', 'relative_humidity': '53.3'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.01G', 'max_wind_speed': '12', 'windspeed_knots': '6.6', 'created_time': '2019-05-28 01:06:19', 'latitude': '-35.364', 'longitude': '141.063', 'air_temperature_celcius': '15', 'relative_humidity': '51.9'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '16.9', 'windspeed_knots': '7.7', 'created_time': '2019-05-28 01:06:24', 'latitude': '-36.0005', 'longitude': '143.1847', 'air_temperature_celcius': '17', 'relative_humidity': '52.5'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.04G', 'max_wind_speed': '22', 'windspeed_knots': '12.2', 'created_time': '2019-05-28 01:06:29', 'latitude': '-37.583', 'longitude': '149.316', 'air_temperature_celcius': '25', 'relative_humidity': '58.3'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '13', 'windspeed_knots': '9.3', 'created_time': '2019-05-28 01:06:35', 'latitude': '-37.611', 'longitude': '149.277', 'air_temperature_celcius': '18', 'relative_humidity': '49.4'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '14', 'windspeed_knots': '9.4', 'created_time': '2019-05-28 01:06:40', 'latitude': '-37.368', 'longitude': '148.05', 'air_temperature_celcius': '10', 'relative_humidity': '41.4'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '12', 'windspeed_knots': '6.8', 'created_time': '2019-05-28 01:06:45', 'latitude': '-37.62', 'longitude': '149.294', 'air_temperature_celcius': '21', 'relative_humidity': '60.4'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '15.9', 'windspeed_knots': '11.5', 'created_time': '2019-05-28 01:06:50', 'latitude': '-37.758', 'longitude': '144.693', 'air_temperature_celcius': '20', 'relative_humidity': '58.8'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.00I', 'max_wind_speed': '9.9', 'windspeed_knots': '5.3', 'created_time': '2019-05-28 01:06:55', 'latitude': '-37.249', 'longitude': '143.413', 'air_temperature_celcius': '14', 'relative_humidity': '47.9'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.01G', 'max_wind_speed': '12', 'windspeed_knots': '6.6', 'created_time': '2019-05-28 01:07:00', 'latitude': '-35.364', 'longitude': '141.063', 'air_temperature_celcius': '15', 'relative_humidity': '51.9'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.01G', 'max_wind_speed': '12', 'windspeed_knots': '6.6', 'created_time': '2019-05-28 01:07:05', 'latitude': '-35.364', 'longitude': '141.063', 'air_temperature_celcius': '15', 'relative_humidity': '51.9'}\n",
      "Message published successfully. Data: {'sender_id': 'P1', 'precipitation': ' 0.04G', 'max_wind_speed': '19', 'windspeed_knots': '11.7', 'created_time': '2019-05-28 01:07:10', 'latitude': '-36.098', 'longitude': '143.735', 'air_temperature_celcius': '17', 'relative_humidity': '58.1'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a918d3fcbd30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# publishing the message as json, converted to bytes before sending\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mpublish_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jsondata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# creating an interval of 5 seconds to send the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a918d3fcbd30>\u001b[0m in \u001b[0;36mpublish_message\u001b[0;34m(producer_instance, topic_name, key, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mkey_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#converting the message to bytes to send\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mproducer_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sending the message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mproducer_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flushing the producer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Message published successfully. Data: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# exception in case of any issues encounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/kafka/producer/kafka.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawait_flush_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ensure_valid_record_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/kafka/producer/record_accumulator.py\u001b[0m in \u001b[0;36mawait_flush_completion\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 log.debug('Waiting on produce to %s',\n\u001b[1;32m    528\u001b[0m                           batch.produce_future.topic_partition)\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKafkaTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timeout waiting for future'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/kafka/producer/future.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# wait() on python2.6 returns None instead of the flag value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "import datetime as dt\n",
    "        \n",
    "        \n",
    "def publish_message(producer_instance, topic_name, key, data):\n",
    "    try:\n",
    "        key_bytes = bytes(key, encoding='utf-8')  #converting the message to bytes to send\n",
    "        producer_instance.send(topic_name, key=key_bytes, value=data) #sending the message\n",
    "        producer_instance.flush() # flushing the producer\n",
    "        print('Message published successfully. Data: ' + str(data))\n",
    "    except Exception as ex: # exception in case of any issues encounters\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        # connecting to the Kafka server and creating the KafkaProducer object\n",
    "        _producer = KafkaProducer(bootstrap_servers=['localhost:9092'], \n",
    "                                  value_serializer=lambda x:dumps(x).encode('ascii'),\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    topic = 'climate' #Topic for Kafka is climate\n",
    "    \n",
    "    print('Publishing records..')\n",
    "    while True:\n",
    "        producer = connect_kafka_producer() # connecting to the Kafka and using its object to send messages\n",
    "        try:\n",
    "            data = climate_streaming[random.randrange(len(climate_streaming)-1)] # random feeding of the messages\n",
    "            # appending the created_time as current_timestamp\n",
    "            data['created_time']=str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')) \n",
    "            # publishing the message as json, converted to bytes before sending\n",
    "            publish_message(producer, topic, 'jsondata', data) \n",
    "            sleep(5)  # creating an interval of 5 seconds to send the data\n",
    "        finally:\n",
    "            producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FIT5148 - TCP_Server.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
